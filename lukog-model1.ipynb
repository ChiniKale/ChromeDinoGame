{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Initialize Pygame\n",
    "pygame.init()\n",
    "\n",
    "# Define window dimensions and other parameters\n",
    "WINDOW_WIDTH = 600\n",
    "WINDOW_HEIGHT = 400\n",
    "GRID_SIZE = 20\n",
    "FPS = 10\n",
    "\n",
    "# Colors (black for background)\n",
    "BLACK = (0, 0, 0)\n",
    "\n",
    "# Initialize the game window\n",
    "screen = pygame.display.set_mode((WINDOW_WIDTH, WINDOW_HEIGHT))\n",
    "pygame.display.set_caption(\"RL Agent Playing Game\")\n",
    "clock = pygame.time.Clock()\n",
    "\n",
    "# Load your assets (using your old variables and file paths)\n",
    "player_image_path = \"dinorun0000.png\"  # Example, replace with your actual file path\n",
    "target_image_path = \"ground.png\"  # Example, replace with your actual file path\n",
    "\n",
    "# Load images for player and target\n",
    "player_image = pygame.image.load(player_image_path)\n",
    "target_image = pygame.image.load(target_image_path)\n",
    "\n",
    "# Resize images to fit within the grid\n",
    "player_image = pygame.transform.scale(player_image, (GRID_SIZE, GRID_SIZE))\n",
    "target_image = pygame.transform.scale(target_image, (GRID_SIZE, GRID_SIZE))\n",
    "\n",
    "# Define the environment (simple grid-based game)\n",
    "class GameEnv:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        # Starting position of the player (centered)\n",
    "        self.player_pos = [WINDOW_WIDTH // 2, WINDOW_HEIGHT // 2]\n",
    "        # Random position for the target\n",
    "        self.target_pos = [\n",
    "            random.randint(0, (WINDOW_WIDTH - GRID_SIZE) // GRID_SIZE) * GRID_SIZE,\n",
    "            random.randint(0, (WINDOW_HEIGHT - GRID_SIZE) // GRID_SIZE) * GRID_SIZE,\n",
    "        ]\n",
    "        # State: (player x, player y, target x, target y)\n",
    "        self.state = (self.player_pos[0], self.player_pos[1], self.target_pos[0], self.target_pos[1])\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        # Actions: 0 = up, 1 = down, 2 = left, 3 = right\n",
    "        if action == 0 and self.player_pos[1] > 0:\n",
    "            self.player_pos[1] -= GRID_SIZE\n",
    "        elif action == 1 and self.player_pos[1] < WINDOW_HEIGHT - GRID_SIZE:\n",
    "            self.player_pos[1] += GRID_SIZE\n",
    "        elif action == 2 and self.player_pos[0] > 0:\n",
    "            self.player_pos[0] -= GRID_SIZE\n",
    "        elif action == 3 and self.player_pos[0] < WINDOW_WIDTH - GRID_SIZE:\n",
    "            self.player_pos[0] += GRID_SIZE\n",
    "\n",
    "        # Check if the player reaches the target\n",
    "        done = self.player_pos == self.target_pos\n",
    "        reward = 1 if done else -0.1  # Reward for reaching the target\n",
    "\n",
    "        # Update the state\n",
    "        self.state = (self.player_pos[0], self.player_pos[1], self.target_pos[0], self.target_pos[1])\n",
    "        return self.state, reward, done\n",
    "\n",
    "    def render(self):\n",
    "        screen.fill(BLACK)\n",
    "        # Draw the player and target at their respective positions\n",
    "        screen.blit(player_image, (self.player_pos[0], self.player_pos[1]))\n",
    "        screen.blit(target_image, (self.target_pos[0], self.target_pos[1]))\n",
    "        pygame.display.flip()\n",
    "\n",
    "# Define the Q-Learning agent\n",
    "class QLearningAgent:\n",
    "    def __init__(self, state_space, action_space, alpha=0.1, gamma=0.9, epsilon=1.0, epsilon_decay=0.995):\n",
    "        self.q_table = np.zeros(state_space + (action_space,))\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.action_space = action_space\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        if random.random() < self.epsilon:\n",
    "            return random.randint(0, self.action_space - 1)  # Explore\n",
    "        return np.argmax(self.q_table[state])  # Exploit\n",
    "\n",
    "    def learn(self, state, action, reward, next_state):\n",
    "        max_next_q = np.max(self.q_table[next_state])\n",
    "        self.q_table[state][action] += self.alpha * (reward + self.gamma * max_next_q - self.q_table[state][action])\n",
    "        self.epsilon *= self.epsilon_decay\n",
    "\n",
    "# Main training and playing loop\n",
    "def train_and_play():\n",
    "    env = GameEnv()\n",
    "    # Discretizing state space: dividing by grid size to get grid-based positions\n",
    "    state_space = (WINDOW_WIDTH // GRID_SIZE, WINDOW_HEIGHT // GRID_SIZE, WINDOW_WIDTH // GRID_SIZE, WINDOW_HEIGHT // GRID_SIZE)\n",
    "    action_space = 4  # up, down, left, right\n",
    "    agent = QLearningAgent(state_space, action_space)\n",
    "\n",
    "    episodes = 500  # Number of training episodes\n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            # Scale state to discrete grid positions\n",
    "            state_scaled = tuple(s // GRID_SIZE for s in state)\n",
    "            action = agent.choose_action(state_scaled)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            next_state_scaled = tuple(s // GRID_SIZE for s in next_state)\n",
    "            agent.learn(state_scaled, action, reward, next_state_scaled)\n",
    "            state = next_state\n",
    "\n",
    "        if episode % 50 == 0:\n",
    "            print(f\"Episode {episode}, Epsilon: {agent.epsilon:.2f}\")\n",
    "\n",
    "    # Play the game after training\n",
    "    print(\"Training complete! Watch the agent play...\")\n",
    "    time.sleep(2)\n",
    "    for _ in range(10):  # Let the agent play 10 episodes\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            env.render()\n",
    "            state_scaled = tuple(s // GRID_SIZE for s in state)\n",
    "            action = np.argmax(agent.q_table[state_scaled])  # Use the trained policy\n",
    "            state, _, done = env.step(action)\n",
    "            clock.tick(FPS)\n",
    "\n",
    "    pygame.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_and_play()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
